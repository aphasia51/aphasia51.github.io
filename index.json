[{"categories":["设计模式"],"content":"设计模式 ","date":"2022-10-05","objectID":"/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:0:0","series":[],"tags":["设计模式"],"title":"Go与设计模式","uri":"/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/#"},{"categories":["设计模式"],"content":" 单一职责原则类的职责单一，对外只提供一种功能， 而引起类变化的原因都应该只有一个 如果一个类的承担了太多的职责，那么当一个职责发生变化时，可能会影响到这个类实现其他职责的能力，并且当客户端需要该对象的某一个职责的时候，不得不将其他不需要的职责也全都包含进来，造成代码的冗余。 package main import ( \"fmt\" ) type ClothesShop struct { } func (cs *ClothesShop) Style() { fmt.Println(\"逛街的装扮\") } type ClothesWork struct { } func (cs *ClothesWork) Style() { fmt.Println(\"工作的装扮\") } func main() { // 工作的业务 cw := ClothesWork{} cw.Style() // 逛街的业务 cs := ClothesShop{} cs.Style() } 每个类的职责尽量设置为单一，对外只提供一种功能. ","date":"2022-10-05","objectID":"/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:1:0","series":[],"tags":["设计模式"],"title":"Go与设计模式","uri":"/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/#单一职责原则"},{"categories":["设计模式"],"content":" 开闭原则类的改动通过增加代码进行，而不是修改源代码 package main import \"fmt\" // 抽象的业务员 type AbstractBanker interface { DoBusi() // 抽象处理业务接口 } // 存款的业务员 type SaveBanker struct { } func (sb *SaveBanker) DoBusi() { fmt.Println(\"进行了存款\") } // 转账的业务员 type TransferBanker struct { } func (sb *TransferBanker) DoBusi() { fmt.Println(\"进行了转账\") } // 取钱的业务员 type WithdrawBanker struct { } func (wb *WithdrawBanker) DoBusi() { fmt.Println(\"进行了取款\") } // 实现一个架构层(基于抽象层进行业务封装--针对interface接口进行封装) func BankBusiness(banker AbstractBanker) { // 通过接口向下调用 banker.DoBusi() } func main() { /* // 存款业务 sb := SaveBanker{} sb.DoBusi() // 转账业务 tb := TransferBanker{} tb.DoBusi() // 取钱业务 wb := WithdrawBanker{} wb.DoBusi() */ // 存款业务 BankBusiness(\u0026SaveBanker{}) // 转账业务 BankBusiness(\u0026TransferBanker{}) // 取钱业务 BankBusiness(\u0026WithdrawBanker{}) } 将银行业务员的职责按照业务分开，后续在有新的业务时，可以通过增加代码实现对应的DoBusi方法，而不用修改原来的代码. ","date":"2022-10-05","objectID":"/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:2:0","series":[],"tags":["设计模式"],"title":"Go与设计模式","uri":"/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/#开闭原则"},{"categories":[],"content":"图解Redis数据持久化 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:0:0","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#"},{"categories":[],"content":" Redis","date":"2022-07-26","objectID":"/redis-aof-rdb/:0:0","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#redis"},{"categories":[],"content":" 常见数据类型及数据结构 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:1:0","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#常见数据类型及数据结构"},{"categories":[],"content":" 数据持久化","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:0","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#数据持久化"},{"categories":[],"content":" AOF 保存写操作到日志的持久化方式，默认不开启(appendonly yes) 记录在AOF日志中的内容，会先在redis成功执行后再写入。这么做有两个好处： 避免额外的检查开销 不会阻塞当前命令的执行 但是如果命令在执行后，写入日志前服务器宕机，该条数据就有丢失的风险。 写操作执行完成再写入到AOF日志中虽不会阻塞当前操作，但有可能会阻塞下一个操作，因为命令写入日志这个动作是由主线程完成，磁盘I/O压力大时，写操作会变得很慢。 从以上两点可知，风险的发生都和写入磁盘的时机有关，所以Redis给我们提供了3种写回策略。 写回策略Redis写入AOF日志的流程: 三种写回策略实际上就是决定内核缓冲区的数据何时写入到磁盘 写回策略 写回时机 优点 缺点 Always 同步写回 数据丢失可能性最小，可靠性比较高 每次写命令都需要落盘，性能消耗大 Everysec 每秒写回 性能适中 宕机时丢失1秒内数据 No 不主动写回，由内核决定 性能最好 宕机时可能会丢失较多数据 实际上，这三种策略就是在控制fsync系统调用的发生的时机，内核将aof_buf文件的数据复制到内核缓冲区中就会进入队列，等待内核决定何时写入硬盘。 Always策略：每次写入AOF文件数据后，立马执行fsync(); Everysec策略：异步定时任务来执行fsync(); No策略：不执行fsync(); 上面我们一直在说将数据写入AOF日志，那么AOF日志就会越来越大，如果Redis需要重启，那么数据的回复也是一个比较耗时的过程(我们都知道AOF日志中记录的是其他格式的命令，所以文件过大，命令重放就会很慢)。所以就有了AOF重写机制 AOF重写机制重写时候，扫描当前数据库中的所有键值对，将每一个键值对用一条命令记录到新的AOF文件，全部记录后再替换。很容易想到，如果之前我们对一个键值对中的值执行了更新操作，那么新的AOF文件中就只会记录最新的键值对对应的命令，之前的更新操作不会再记录，这样一来AOF文件就会压缩。但是仔细一想，重写的过程是比较耗时的，所以需要主进程fork一个子进程来bgrewriteaof完成这个操作。 既然需要fork子进程，那fork时就一定会阻塞主进程，虽然fork会采用写时复制机制，但是fork子进程也需要拷贝必要的数据结构(内存页表等)，这个拷贝的过程也需要消耗大量CPU资源，也就是说在fork完成前主进程是阻塞的。 拷贝内存页表完成后，父子进程才指向相同的内存地址空间，但子进程并没有申请与父进程同样大小的内存，这里就会用到写时复制机制了，就是字面意思-写得时候才会复制，即拷贝真正的数据。 这里可能会有人有疑问，为什么不直接在现有的AOF日志文件中操作，而要新创建一个文件？ 上面我们提到，会有子进程来完成AOF文件的写入，如果复用AOF文件，那么必然产生父子进程竞争问题，影响父进程性能。 如果我们在重写时失败，那么可能会造成原来的AOF文件也被污染而无法使用。用新的AOF文件，即使失败，直接删除即可。 前面我们提到AOF重写是子进程bgrewriteaof来完成的，既然是子进程，那么就不会影响主进程的操作，也不会阻塞主进程。那为什么使用子进程而不是子线程呢？ 设想如果我们使用了子线程，在修改共享内存数据的时候需要加锁来保证安全，可想而知性能就会降低。如果使用子进程，虽然父子进程也会共享内存数据，但是这个共享的内存是以只读的方式，就是说当父子进程任一方修改了数据，就会发生写时复制，这样父子进程就拥有了独立的数据副本，不用加锁来保证数据安全。 什么是写时复制？在Linux中，调用fork系统调用创建子进程时候，并不会复制父进程的内存页，而是与父进程共用相同的内存页，只有当父子进程的任一方对内存页做修改时才会进行复制，这就是写时复制。 原理1、创建子进程时，父进程的虚拟内存与物理内存关系会复制一份给子进程，并把内存设置为只读。这里父子进程共享内存数据，这样做有两个好处： 加速子进程的创建 减少进程对物理内存的占用 这里把内存设置为只读，是为了当对内存进行写操作时，会触发缺页异常(无写权限，无法获取数据)，这样内核在缺页异常处理函数中就可以进行内存页的复制。 2、当父进程或子进程对内存数据做出修改时候，就会触发写时复制。这里会复制内存页，并重新设置映射关系，同时将父子进程的虚拟页设置为可读写，即父子进程拥有了各自的虚拟内存与对应的物理内存。 话说回来，让我们继续看看AOF重写。 上面已经说过，子进程重写过程中主进程会正常处理命令，如果此时主进程修改了已存在的键值对就会发生写时复制。这里值得注意的地方是写时复制机制此时只会复制主进程修改的物理内存数据，没有修改物理内存子进程还是会和父进程共享。这里就能提出一个问题，修改数据后，父子进程的内存数据就不一样了，这可咋整呢？ Redis设置了一个AOF重写缓冲区来解决这个问题，这个缓冲区在创建bgrewriteaof子进程后开始使用，即重写AOF时，Redis成功执行完一个命令后会把这个命令写到AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写后，会向主进程发送一条信号(异步),主进程收到该信号以后，就会将AOF重写缓冲区的内容追加到新的AOF文件中，然后用新的AOF文件覆盖当前AOF文件。至此，完成AOF重写操作。 另外，如果此时主进程修改的是一个bigkey(value很大，不是key很大)，那么父进程在申请内存时阻塞的风险就会提高，复制物理内存也比较耗时，有阻塞主进程的风险， 总结整个AOF持久化机制中，有哪些操作可能会阻塞主进程？ 命令执行完，写入AOF日志操作完成前。写入AOF日志这个操作是主进程完成的，如果此时磁盘写压力大，那么在写入该命令时就可能发生阻塞，导致后续的操作无法正常进行。 主进程fork子进程进行AOF重写时，系统调用fork操作一定会阻塞主进程。 写时复制时，父进程操作大key，重新申请大块内存时间耗时就会变长，造成父进程阻塞。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:1","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#aof"},{"categories":[],"content":" AOF 保存写操作到日志的持久化方式，默认不开启(appendonly yes) 记录在AOF日志中的内容，会先在redis成功执行后再写入。这么做有两个好处： 避免额外的检查开销 不会阻塞当前命令的执行 但是如果命令在执行后，写入日志前服务器宕机，该条数据就有丢失的风险。 写操作执行完成再写入到AOF日志中虽不会阻塞当前操作，但有可能会阻塞下一个操作，因为命令写入日志这个动作是由主线程完成，磁盘I/O压力大时，写操作会变得很慢。 从以上两点可知，风险的发生都和写入磁盘的时机有关，所以Redis给我们提供了3种写回策略。 写回策略Redis写入AOF日志的流程: 三种写回策略实际上就是决定内核缓冲区的数据何时写入到磁盘 写回策略 写回时机 优点 缺点 Always 同步写回 数据丢失可能性最小，可靠性比较高 每次写命令都需要落盘，性能消耗大 Everysec 每秒写回 性能适中 宕机时丢失1秒内数据 No 不主动写回，由内核决定 性能最好 宕机时可能会丢失较多数据 实际上，这三种策略就是在控制fsync系统调用的发生的时机，内核将aof_buf文件的数据复制到内核缓冲区中就会进入队列，等待内核决定何时写入硬盘。 Always策略：每次写入AOF文件数据后，立马执行fsync(); Everysec策略：异步定时任务来执行fsync(); No策略：不执行fsync(); 上面我们一直在说将数据写入AOF日志，那么AOF日志就会越来越大，如果Redis需要重启，那么数据的回复也是一个比较耗时的过程(我们都知道AOF日志中记录的是其他格式的命令，所以文件过大，命令重放就会很慢)。所以就有了AOF重写机制 AOF重写机制重写时候，扫描当前数据库中的所有键值对，将每一个键值对用一条命令记录到新的AOF文件，全部记录后再替换。很容易想到，如果之前我们对一个键值对中的值执行了更新操作，那么新的AOF文件中就只会记录最新的键值对对应的命令，之前的更新操作不会再记录，这样一来AOF文件就会压缩。但是仔细一想，重写的过程是比较耗时的，所以需要主进程fork一个子进程来bgrewriteaof完成这个操作。 既然需要fork子进程，那fork时就一定会阻塞主进程，虽然fork会采用写时复制机制，但是fork子进程也需要拷贝必要的数据结构(内存页表等)，这个拷贝的过程也需要消耗大量CPU资源，也就是说在fork完成前主进程是阻塞的。 拷贝内存页表完成后，父子进程才指向相同的内存地址空间，但子进程并没有申请与父进程同样大小的内存，这里就会用到写时复制机制了，就是字面意思-写得时候才会复制，即拷贝真正的数据。 这里可能会有人有疑问，为什么不直接在现有的AOF日志文件中操作，而要新创建一个文件？ 上面我们提到，会有子进程来完成AOF文件的写入，如果复用AOF文件，那么必然产生父子进程竞争问题，影响父进程性能。 如果我们在重写时失败，那么可能会造成原来的AOF文件也被污染而无法使用。用新的AOF文件，即使失败，直接删除即可。 前面我们提到AOF重写是子进程bgrewriteaof来完成的，既然是子进程，那么就不会影响主进程的操作，也不会阻塞主进程。那为什么使用子进程而不是子线程呢？ 设想如果我们使用了子线程，在修改共享内存数据的时候需要加锁来保证安全，可想而知性能就会降低。如果使用子进程，虽然父子进程也会共享内存数据，但是这个共享的内存是以只读的方式，就是说当父子进程任一方修改了数据，就会发生写时复制，这样父子进程就拥有了独立的数据副本，不用加锁来保证数据安全。 什么是写时复制？在Linux中，调用fork系统调用创建子进程时候，并不会复制父进程的内存页，而是与父进程共用相同的内存页，只有当父子进程的任一方对内存页做修改时才会进行复制，这就是写时复制。 原理1、创建子进程时，父进程的虚拟内存与物理内存关系会复制一份给子进程，并把内存设置为只读。这里父子进程共享内存数据，这样做有两个好处： 加速子进程的创建 减少进程对物理内存的占用 这里把内存设置为只读，是为了当对内存进行写操作时，会触发缺页异常(无写权限，无法获取数据)，这样内核在缺页异常处理函数中就可以进行内存页的复制。 2、当父进程或子进程对内存数据做出修改时候，就会触发写时复制。这里会复制内存页，并重新设置映射关系，同时将父子进程的虚拟页设置为可读写，即父子进程拥有了各自的虚拟内存与对应的物理内存。 话说回来，让我们继续看看AOF重写。 上面已经说过，子进程重写过程中主进程会正常处理命令，如果此时主进程修改了已存在的键值对就会发生写时复制。这里值得注意的地方是写时复制机制此时只会复制主进程修改的物理内存数据，没有修改物理内存子进程还是会和父进程共享。这里就能提出一个问题，修改数据后，父子进程的内存数据就不一样了，这可咋整呢？ Redis设置了一个AOF重写缓冲区来解决这个问题，这个缓冲区在创建bgrewriteaof子进程后开始使用，即重写AOF时，Redis成功执行完一个命令后会把这个命令写到AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写后，会向主进程发送一条信号(异步),主进程收到该信号以后，就会将AOF重写缓冲区的内容追加到新的AOF文件中，然后用新的AOF文件覆盖当前AOF文件。至此，完成AOF重写操作。 另外，如果此时主进程修改的是一个bigkey(value很大，不是key很大)，那么父进程在申请内存时阻塞的风险就会提高，复制物理内存也比较耗时，有阻塞主进程的风险， 总结整个AOF持久化机制中，有哪些操作可能会阻塞主进程？ 命令执行完，写入AOF日志操作完成前。写入AOF日志这个操作是主进程完成的，如果此时磁盘写压力大，那么在写入该命令时就可能发生阻塞，导致后续的操作无法正常进行。 主进程fork子进程进行AOF重写时，系统调用fork操作一定会阻塞主进程。 写时复制时，父进程操作大key，重新申请大块内存时间耗时就会变长，造成父进程阻塞。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:1","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#写回策略"},{"categories":[],"content":" AOF 保存写操作到日志的持久化方式，默认不开启(appendonly yes) 记录在AOF日志中的内容，会先在redis成功执行后再写入。这么做有两个好处： 避免额外的检查开销 不会阻塞当前命令的执行 但是如果命令在执行后，写入日志前服务器宕机，该条数据就有丢失的风险。 写操作执行完成再写入到AOF日志中虽不会阻塞当前操作，但有可能会阻塞下一个操作，因为命令写入日志这个动作是由主线程完成，磁盘I/O压力大时，写操作会变得很慢。 从以上两点可知，风险的发生都和写入磁盘的时机有关，所以Redis给我们提供了3种写回策略。 写回策略Redis写入AOF日志的流程: 三种写回策略实际上就是决定内核缓冲区的数据何时写入到磁盘 写回策略 写回时机 优点 缺点 Always 同步写回 数据丢失可能性最小，可靠性比较高 每次写命令都需要落盘，性能消耗大 Everysec 每秒写回 性能适中 宕机时丢失1秒内数据 No 不主动写回，由内核决定 性能最好 宕机时可能会丢失较多数据 实际上，这三种策略就是在控制fsync系统调用的发生的时机，内核将aof_buf文件的数据复制到内核缓冲区中就会进入队列，等待内核决定何时写入硬盘。 Always策略：每次写入AOF文件数据后，立马执行fsync(); Everysec策略：异步定时任务来执行fsync(); No策略：不执行fsync(); 上面我们一直在说将数据写入AOF日志，那么AOF日志就会越来越大，如果Redis需要重启，那么数据的回复也是一个比较耗时的过程(我们都知道AOF日志中记录的是其他格式的命令，所以文件过大，命令重放就会很慢)。所以就有了AOF重写机制 AOF重写机制重写时候，扫描当前数据库中的所有键值对，将每一个键值对用一条命令记录到新的AOF文件，全部记录后再替换。很容易想到，如果之前我们对一个键值对中的值执行了更新操作，那么新的AOF文件中就只会记录最新的键值对对应的命令，之前的更新操作不会再记录，这样一来AOF文件就会压缩。但是仔细一想，重写的过程是比较耗时的，所以需要主进程fork一个子进程来bgrewriteaof完成这个操作。 既然需要fork子进程，那fork时就一定会阻塞主进程，虽然fork会采用写时复制机制，但是fork子进程也需要拷贝必要的数据结构(内存页表等)，这个拷贝的过程也需要消耗大量CPU资源，也就是说在fork完成前主进程是阻塞的。 拷贝内存页表完成后，父子进程才指向相同的内存地址空间，但子进程并没有申请与父进程同样大小的内存，这里就会用到写时复制机制了，就是字面意思-写得时候才会复制，即拷贝真正的数据。 这里可能会有人有疑问，为什么不直接在现有的AOF日志文件中操作，而要新创建一个文件？ 上面我们提到，会有子进程来完成AOF文件的写入，如果复用AOF文件，那么必然产生父子进程竞争问题，影响父进程性能。 如果我们在重写时失败，那么可能会造成原来的AOF文件也被污染而无法使用。用新的AOF文件，即使失败，直接删除即可。 前面我们提到AOF重写是子进程bgrewriteaof来完成的，既然是子进程，那么就不会影响主进程的操作，也不会阻塞主进程。那为什么使用子进程而不是子线程呢？ 设想如果我们使用了子线程，在修改共享内存数据的时候需要加锁来保证安全，可想而知性能就会降低。如果使用子进程，虽然父子进程也会共享内存数据，但是这个共享的内存是以只读的方式，就是说当父子进程任一方修改了数据，就会发生写时复制，这样父子进程就拥有了独立的数据副本，不用加锁来保证数据安全。 什么是写时复制？在Linux中，调用fork系统调用创建子进程时候，并不会复制父进程的内存页，而是与父进程共用相同的内存页，只有当父子进程的任一方对内存页做修改时才会进行复制，这就是写时复制。 原理1、创建子进程时，父进程的虚拟内存与物理内存关系会复制一份给子进程，并把内存设置为只读。这里父子进程共享内存数据，这样做有两个好处： 加速子进程的创建 减少进程对物理内存的占用 这里把内存设置为只读，是为了当对内存进行写操作时，会触发缺页异常(无写权限，无法获取数据)，这样内核在缺页异常处理函数中就可以进行内存页的复制。 2、当父进程或子进程对内存数据做出修改时候，就会触发写时复制。这里会复制内存页，并重新设置映射关系，同时将父子进程的虚拟页设置为可读写，即父子进程拥有了各自的虚拟内存与对应的物理内存。 话说回来，让我们继续看看AOF重写。 上面已经说过，子进程重写过程中主进程会正常处理命令，如果此时主进程修改了已存在的键值对就会发生写时复制。这里值得注意的地方是写时复制机制此时只会复制主进程修改的物理内存数据，没有修改物理内存子进程还是会和父进程共享。这里就能提出一个问题，修改数据后，父子进程的内存数据就不一样了，这可咋整呢？ Redis设置了一个AOF重写缓冲区来解决这个问题，这个缓冲区在创建bgrewriteaof子进程后开始使用，即重写AOF时，Redis成功执行完一个命令后会把这个命令写到AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写后，会向主进程发送一条信号(异步),主进程收到该信号以后，就会将AOF重写缓冲区的内容追加到新的AOF文件中，然后用新的AOF文件覆盖当前AOF文件。至此，完成AOF重写操作。 另外，如果此时主进程修改的是一个bigkey(value很大，不是key很大)，那么父进程在申请内存时阻塞的风险就会提高，复制物理内存也比较耗时，有阻塞主进程的风险， 总结整个AOF持久化机制中，有哪些操作可能会阻塞主进程？ 命令执行完，写入AOF日志操作完成前。写入AOF日志这个操作是主进程完成的，如果此时磁盘写压力大，那么在写入该命令时就可能发生阻塞，导致后续的操作无法正常进行。 主进程fork子进程进行AOF重写时，系统调用fork操作一定会阻塞主进程。 写时复制时，父进程操作大key，重新申请大块内存时间耗时就会变长，造成父进程阻塞。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:1","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#aof重写机制"},{"categories":[],"content":" AOF 保存写操作到日志的持久化方式，默认不开启(appendonly yes) 记录在AOF日志中的内容，会先在redis成功执行后再写入。这么做有两个好处： 避免额外的检查开销 不会阻塞当前命令的执行 但是如果命令在执行后，写入日志前服务器宕机，该条数据就有丢失的风险。 写操作执行完成再写入到AOF日志中虽不会阻塞当前操作，但有可能会阻塞下一个操作，因为命令写入日志这个动作是由主线程完成，磁盘I/O压力大时，写操作会变得很慢。 从以上两点可知，风险的发生都和写入磁盘的时机有关，所以Redis给我们提供了3种写回策略。 写回策略Redis写入AOF日志的流程: 三种写回策略实际上就是决定内核缓冲区的数据何时写入到磁盘 写回策略 写回时机 优点 缺点 Always 同步写回 数据丢失可能性最小，可靠性比较高 每次写命令都需要落盘，性能消耗大 Everysec 每秒写回 性能适中 宕机时丢失1秒内数据 No 不主动写回，由内核决定 性能最好 宕机时可能会丢失较多数据 实际上，这三种策略就是在控制fsync系统调用的发生的时机，内核将aof_buf文件的数据复制到内核缓冲区中就会进入队列，等待内核决定何时写入硬盘。 Always策略：每次写入AOF文件数据后，立马执行fsync(); Everysec策略：异步定时任务来执行fsync(); No策略：不执行fsync(); 上面我们一直在说将数据写入AOF日志，那么AOF日志就会越来越大，如果Redis需要重启，那么数据的回复也是一个比较耗时的过程(我们都知道AOF日志中记录的是其他格式的命令，所以文件过大，命令重放就会很慢)。所以就有了AOF重写机制 AOF重写机制重写时候，扫描当前数据库中的所有键值对，将每一个键值对用一条命令记录到新的AOF文件，全部记录后再替换。很容易想到，如果之前我们对一个键值对中的值执行了更新操作，那么新的AOF文件中就只会记录最新的键值对对应的命令，之前的更新操作不会再记录，这样一来AOF文件就会压缩。但是仔细一想，重写的过程是比较耗时的，所以需要主进程fork一个子进程来bgrewriteaof完成这个操作。 既然需要fork子进程，那fork时就一定会阻塞主进程，虽然fork会采用写时复制机制，但是fork子进程也需要拷贝必要的数据结构(内存页表等)，这个拷贝的过程也需要消耗大量CPU资源，也就是说在fork完成前主进程是阻塞的。 拷贝内存页表完成后，父子进程才指向相同的内存地址空间，但子进程并没有申请与父进程同样大小的内存，这里就会用到写时复制机制了，就是字面意思-写得时候才会复制，即拷贝真正的数据。 这里可能会有人有疑问，为什么不直接在现有的AOF日志文件中操作，而要新创建一个文件？ 上面我们提到，会有子进程来完成AOF文件的写入，如果复用AOF文件，那么必然产生父子进程竞争问题，影响父进程性能。 如果我们在重写时失败，那么可能会造成原来的AOF文件也被污染而无法使用。用新的AOF文件，即使失败，直接删除即可。 前面我们提到AOF重写是子进程bgrewriteaof来完成的，既然是子进程，那么就不会影响主进程的操作，也不会阻塞主进程。那为什么使用子进程而不是子线程呢？ 设想如果我们使用了子线程，在修改共享内存数据的时候需要加锁来保证安全，可想而知性能就会降低。如果使用子进程，虽然父子进程也会共享内存数据，但是这个共享的内存是以只读的方式，就是说当父子进程任一方修改了数据，就会发生写时复制，这样父子进程就拥有了独立的数据副本，不用加锁来保证数据安全。 什么是写时复制？在Linux中，调用fork系统调用创建子进程时候，并不会复制父进程的内存页，而是与父进程共用相同的内存页，只有当父子进程的任一方对内存页做修改时才会进行复制，这就是写时复制。 原理1、创建子进程时，父进程的虚拟内存与物理内存关系会复制一份给子进程，并把内存设置为只读。这里父子进程共享内存数据，这样做有两个好处： 加速子进程的创建 减少进程对物理内存的占用 这里把内存设置为只读，是为了当对内存进行写操作时，会触发缺页异常(无写权限，无法获取数据)，这样内核在缺页异常处理函数中就可以进行内存页的复制。 2、当父进程或子进程对内存数据做出修改时候，就会触发写时复制。这里会复制内存页，并重新设置映射关系，同时将父子进程的虚拟页设置为可读写，即父子进程拥有了各自的虚拟内存与对应的物理内存。 话说回来，让我们继续看看AOF重写。 上面已经说过，子进程重写过程中主进程会正常处理命令，如果此时主进程修改了已存在的键值对就会发生写时复制。这里值得注意的地方是写时复制机制此时只会复制主进程修改的物理内存数据，没有修改物理内存子进程还是会和父进程共享。这里就能提出一个问题，修改数据后，父子进程的内存数据就不一样了，这可咋整呢？ Redis设置了一个AOF重写缓冲区来解决这个问题，这个缓冲区在创建bgrewriteaof子进程后开始使用，即重写AOF时，Redis成功执行完一个命令后会把这个命令写到AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写后，会向主进程发送一条信号(异步),主进程收到该信号以后，就会将AOF重写缓冲区的内容追加到新的AOF文件中，然后用新的AOF文件覆盖当前AOF文件。至此，完成AOF重写操作。 另外，如果此时主进程修改的是一个bigkey(value很大，不是key很大)，那么父进程在申请内存时阻塞的风险就会提高，复制物理内存也比较耗时，有阻塞主进程的风险， 总结整个AOF持久化机制中，有哪些操作可能会阻塞主进程？ 命令执行完，写入AOF日志操作完成前。写入AOF日志这个操作是主进程完成的，如果此时磁盘写压力大，那么在写入该命令时就可能发生阻塞，导致后续的操作无法正常进行。 主进程fork子进程进行AOF重写时，系统调用fork操作一定会阻塞主进程。 写时复制时，父进程操作大key，重新申请大块内存时间耗时就会变长，造成父进程阻塞。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:1","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#什么是写时复制"},{"categories":[],"content":" AOF 保存写操作到日志的持久化方式，默认不开启(appendonly yes) 记录在AOF日志中的内容，会先在redis成功执行后再写入。这么做有两个好处： 避免额外的检查开销 不会阻塞当前命令的执行 但是如果命令在执行后，写入日志前服务器宕机，该条数据就有丢失的风险。 写操作执行完成再写入到AOF日志中虽不会阻塞当前操作，但有可能会阻塞下一个操作，因为命令写入日志这个动作是由主线程完成，磁盘I/O压力大时，写操作会变得很慢。 从以上两点可知，风险的发生都和写入磁盘的时机有关，所以Redis给我们提供了3种写回策略。 写回策略Redis写入AOF日志的流程: 三种写回策略实际上就是决定内核缓冲区的数据何时写入到磁盘 写回策略 写回时机 优点 缺点 Always 同步写回 数据丢失可能性最小，可靠性比较高 每次写命令都需要落盘，性能消耗大 Everysec 每秒写回 性能适中 宕机时丢失1秒内数据 No 不主动写回，由内核决定 性能最好 宕机时可能会丢失较多数据 实际上，这三种策略就是在控制fsync系统调用的发生的时机，内核将aof_buf文件的数据复制到内核缓冲区中就会进入队列，等待内核决定何时写入硬盘。 Always策略：每次写入AOF文件数据后，立马执行fsync(); Everysec策略：异步定时任务来执行fsync(); No策略：不执行fsync(); 上面我们一直在说将数据写入AOF日志，那么AOF日志就会越来越大，如果Redis需要重启，那么数据的回复也是一个比较耗时的过程(我们都知道AOF日志中记录的是其他格式的命令，所以文件过大，命令重放就会很慢)。所以就有了AOF重写机制 AOF重写机制重写时候，扫描当前数据库中的所有键值对，将每一个键值对用一条命令记录到新的AOF文件，全部记录后再替换。很容易想到，如果之前我们对一个键值对中的值执行了更新操作，那么新的AOF文件中就只会记录最新的键值对对应的命令，之前的更新操作不会再记录，这样一来AOF文件就会压缩。但是仔细一想，重写的过程是比较耗时的，所以需要主进程fork一个子进程来bgrewriteaof完成这个操作。 既然需要fork子进程，那fork时就一定会阻塞主进程，虽然fork会采用写时复制机制，但是fork子进程也需要拷贝必要的数据结构(内存页表等)，这个拷贝的过程也需要消耗大量CPU资源，也就是说在fork完成前主进程是阻塞的。 拷贝内存页表完成后，父子进程才指向相同的内存地址空间，但子进程并没有申请与父进程同样大小的内存，这里就会用到写时复制机制了，就是字面意思-写得时候才会复制，即拷贝真正的数据。 这里可能会有人有疑问，为什么不直接在现有的AOF日志文件中操作，而要新创建一个文件？ 上面我们提到，会有子进程来完成AOF文件的写入，如果复用AOF文件，那么必然产生父子进程竞争问题，影响父进程性能。 如果我们在重写时失败，那么可能会造成原来的AOF文件也被污染而无法使用。用新的AOF文件，即使失败，直接删除即可。 前面我们提到AOF重写是子进程bgrewriteaof来完成的，既然是子进程，那么就不会影响主进程的操作，也不会阻塞主进程。那为什么使用子进程而不是子线程呢？ 设想如果我们使用了子线程，在修改共享内存数据的时候需要加锁来保证安全，可想而知性能就会降低。如果使用子进程，虽然父子进程也会共享内存数据，但是这个共享的内存是以只读的方式，就是说当父子进程任一方修改了数据，就会发生写时复制，这样父子进程就拥有了独立的数据副本，不用加锁来保证数据安全。 什么是写时复制？在Linux中，调用fork系统调用创建子进程时候，并不会复制父进程的内存页，而是与父进程共用相同的内存页，只有当父子进程的任一方对内存页做修改时才会进行复制，这就是写时复制。 原理1、创建子进程时，父进程的虚拟内存与物理内存关系会复制一份给子进程，并把内存设置为只读。这里父子进程共享内存数据，这样做有两个好处： 加速子进程的创建 减少进程对物理内存的占用 这里把内存设置为只读，是为了当对内存进行写操作时，会触发缺页异常(无写权限，无法获取数据)，这样内核在缺页异常处理函数中就可以进行内存页的复制。 2、当父进程或子进程对内存数据做出修改时候，就会触发写时复制。这里会复制内存页，并重新设置映射关系，同时将父子进程的虚拟页设置为可读写，即父子进程拥有了各自的虚拟内存与对应的物理内存。 话说回来，让我们继续看看AOF重写。 上面已经说过，子进程重写过程中主进程会正常处理命令，如果此时主进程修改了已存在的键值对就会发生写时复制。这里值得注意的地方是写时复制机制此时只会复制主进程修改的物理内存数据，没有修改物理内存子进程还是会和父进程共享。这里就能提出一个问题，修改数据后，父子进程的内存数据就不一样了，这可咋整呢？ Redis设置了一个AOF重写缓冲区来解决这个问题，这个缓冲区在创建bgrewriteaof子进程后开始使用，即重写AOF时，Redis成功执行完一个命令后会把这个命令写到AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写后，会向主进程发送一条信号(异步),主进程收到该信号以后，就会将AOF重写缓冲区的内容追加到新的AOF文件中，然后用新的AOF文件覆盖当前AOF文件。至此，完成AOF重写操作。 另外，如果此时主进程修改的是一个bigkey(value很大，不是key很大)，那么父进程在申请内存时阻塞的风险就会提高，复制物理内存也比较耗时，有阻塞主进程的风险， 总结整个AOF持久化机制中，有哪些操作可能会阻塞主进程？ 命令执行完，写入AOF日志操作完成前。写入AOF日志这个操作是主进程完成的，如果此时磁盘写压力大，那么在写入该命令时就可能发生阻塞，导致后续的操作无法正常进行。 主进程fork子进程进行AOF重写时，系统调用fork操作一定会阻塞主进程。 写时复制时，父进程操作大key，重新申请大块内存时间耗时就会变长，造成父进程阻塞。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:1","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#原理"},{"categories":[],"content":" AOF 保存写操作到日志的持久化方式，默认不开启(appendonly yes) 记录在AOF日志中的内容，会先在redis成功执行后再写入。这么做有两个好处： 避免额外的检查开销 不会阻塞当前命令的执行 但是如果命令在执行后，写入日志前服务器宕机，该条数据就有丢失的风险。 写操作执行完成再写入到AOF日志中虽不会阻塞当前操作，但有可能会阻塞下一个操作，因为命令写入日志这个动作是由主线程完成，磁盘I/O压力大时，写操作会变得很慢。 从以上两点可知，风险的发生都和写入磁盘的时机有关，所以Redis给我们提供了3种写回策略。 写回策略Redis写入AOF日志的流程: 三种写回策略实际上就是决定内核缓冲区的数据何时写入到磁盘 写回策略 写回时机 优点 缺点 Always 同步写回 数据丢失可能性最小，可靠性比较高 每次写命令都需要落盘，性能消耗大 Everysec 每秒写回 性能适中 宕机时丢失1秒内数据 No 不主动写回，由内核决定 性能最好 宕机时可能会丢失较多数据 实际上，这三种策略就是在控制fsync系统调用的发生的时机，内核将aof_buf文件的数据复制到内核缓冲区中就会进入队列，等待内核决定何时写入硬盘。 Always策略：每次写入AOF文件数据后，立马执行fsync(); Everysec策略：异步定时任务来执行fsync(); No策略：不执行fsync(); 上面我们一直在说将数据写入AOF日志，那么AOF日志就会越来越大，如果Redis需要重启，那么数据的回复也是一个比较耗时的过程(我们都知道AOF日志中记录的是其他格式的命令，所以文件过大，命令重放就会很慢)。所以就有了AOF重写机制 AOF重写机制重写时候，扫描当前数据库中的所有键值对，将每一个键值对用一条命令记录到新的AOF文件，全部记录后再替换。很容易想到，如果之前我们对一个键值对中的值执行了更新操作，那么新的AOF文件中就只会记录最新的键值对对应的命令，之前的更新操作不会再记录，这样一来AOF文件就会压缩。但是仔细一想，重写的过程是比较耗时的，所以需要主进程fork一个子进程来bgrewriteaof完成这个操作。 既然需要fork子进程，那fork时就一定会阻塞主进程，虽然fork会采用写时复制机制，但是fork子进程也需要拷贝必要的数据结构(内存页表等)，这个拷贝的过程也需要消耗大量CPU资源，也就是说在fork完成前主进程是阻塞的。 拷贝内存页表完成后，父子进程才指向相同的内存地址空间，但子进程并没有申请与父进程同样大小的内存，这里就会用到写时复制机制了，就是字面意思-写得时候才会复制，即拷贝真正的数据。 这里可能会有人有疑问，为什么不直接在现有的AOF日志文件中操作，而要新创建一个文件？ 上面我们提到，会有子进程来完成AOF文件的写入，如果复用AOF文件，那么必然产生父子进程竞争问题，影响父进程性能。 如果我们在重写时失败，那么可能会造成原来的AOF文件也被污染而无法使用。用新的AOF文件，即使失败，直接删除即可。 前面我们提到AOF重写是子进程bgrewriteaof来完成的，既然是子进程，那么就不会影响主进程的操作，也不会阻塞主进程。那为什么使用子进程而不是子线程呢？ 设想如果我们使用了子线程，在修改共享内存数据的时候需要加锁来保证安全，可想而知性能就会降低。如果使用子进程，虽然父子进程也会共享内存数据，但是这个共享的内存是以只读的方式，就是说当父子进程任一方修改了数据，就会发生写时复制，这样父子进程就拥有了独立的数据副本，不用加锁来保证数据安全。 什么是写时复制？在Linux中，调用fork系统调用创建子进程时候，并不会复制父进程的内存页，而是与父进程共用相同的内存页，只有当父子进程的任一方对内存页做修改时才会进行复制，这就是写时复制。 原理1、创建子进程时，父进程的虚拟内存与物理内存关系会复制一份给子进程，并把内存设置为只读。这里父子进程共享内存数据，这样做有两个好处： 加速子进程的创建 减少进程对物理内存的占用 这里把内存设置为只读，是为了当对内存进行写操作时，会触发缺页异常(无写权限，无法获取数据)，这样内核在缺页异常处理函数中就可以进行内存页的复制。 2、当父进程或子进程对内存数据做出修改时候，就会触发写时复制。这里会复制内存页，并重新设置映射关系，同时将父子进程的虚拟页设置为可读写，即父子进程拥有了各自的虚拟内存与对应的物理内存。 话说回来，让我们继续看看AOF重写。 上面已经说过，子进程重写过程中主进程会正常处理命令，如果此时主进程修改了已存在的键值对就会发生写时复制。这里值得注意的地方是写时复制机制此时只会复制主进程修改的物理内存数据，没有修改物理内存子进程还是会和父进程共享。这里就能提出一个问题，修改数据后，父子进程的内存数据就不一样了，这可咋整呢？ Redis设置了一个AOF重写缓冲区来解决这个问题，这个缓冲区在创建bgrewriteaof子进程后开始使用，即重写AOF时，Redis成功执行完一个命令后会把这个命令写到AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写后，会向主进程发送一条信号(异步),主进程收到该信号以后，就会将AOF重写缓冲区的内容追加到新的AOF文件中，然后用新的AOF文件覆盖当前AOF文件。至此，完成AOF重写操作。 另外，如果此时主进程修改的是一个bigkey(value很大，不是key很大)，那么父进程在申请内存时阻塞的风险就会提高，复制物理内存也比较耗时，有阻塞主进程的风险， 总结整个AOF持久化机制中，有哪些操作可能会阻塞主进程？ 命令执行完，写入AOF日志操作完成前。写入AOF日志这个操作是主进程完成的，如果此时磁盘写压力大，那么在写入该命令时就可能发生阻塞，导致后续的操作无法正常进行。 主进程fork子进程进行AOF重写时，系统调用fork操作一定会阻塞主进程。 写时复制时，父进程操作大key，重新申请大块内存时间耗时就会变长，造成父进程阻塞。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:1","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#总结"},{"categories":[],"content":" RDBRDB(Redis Database)是Redis数据持久化的另一种方式：内存快照，即记录某一时刻内存中的数据，类似于拍照时记录某一瞬间的形象。 和AOF相比，RDB恢复数据的效率更高，因为RDB快照记录的是实际数据，恢复时直接将RDB文件读入内存就行。 执行RDB快照时，数据还可以修改吗？快照就和自拍一样，拍照时如果自己动了，那么照片就糊了。那么对于RDB而言，它也不希望数据在‘动’。 如果在执行快照期间数据都不能修改的话，那么这肯定会给我们的业务造成很大的影响，这肯定是不能被接受的。 bgsave这一子进程是由主线程fork出来共享主线程内存数据的。如果主线程在执行快照期间是进行的读操作，那么主线程和bgsave子进程就互不影响，如果是执行写操作的话，那么这里就会利用到上面讲到的操作系统提供的写时复制机制: 数据被复制一份，生成数据的副本。bgsave子进程把这个副本数据写入RDB文件，主线程仍然可以直接修改原来的数据。 使用RDB做快照需要注意的点 虽然RDB快照是bgsave子进程执行的，但如果执行快照的间隔太短，一方面频繁的写入数据到磁盘会给磁盘带来压力，另一方面，fork子进程这一过程是会阻塞主线程的，内存越大阻塞时间越长。 那么我们可以做增量快照，即做一次全量快照后，后续只需要记录修改的数据，对修改的数据做快照，减小做快照时候的开销。不过我们要是是以写操作为主的业务或者修改的键值对很多的话，记录被修改的数据同样会带来比较大的开销。 跟AOF相比，虽然RDB的恢复速度更快，但是快照的频率如何确定却也是一个问题。频率高了开销太大，频率小了又会造成数据的丢失。所以Redis 4.0提出了一个混合使用AOF日志和RDB快照的方法，即内存快照以一定的频率执行，两次快照之间用AOF记录这期间的操作。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:2","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#rdb"},{"categories":[],"content":" RDBRDB(Redis Database)是Redis数据持久化的另一种方式：内存快照，即记录某一时刻内存中的数据，类似于拍照时记录某一瞬间的形象。 和AOF相比，RDB恢复数据的效率更高，因为RDB快照记录的是实际数据，恢复时直接将RDB文件读入内存就行。 执行RDB快照时，数据还可以修改吗？快照就和自拍一样，拍照时如果自己动了，那么照片就糊了。那么对于RDB而言，它也不希望数据在‘动’。 如果在执行快照期间数据都不能修改的话，那么这肯定会给我们的业务造成很大的影响，这肯定是不能被接受的。 bgsave这一子进程是由主线程fork出来共享主线程内存数据的。如果主线程在执行快照期间是进行的读操作，那么主线程和bgsave子进程就互不影响，如果是执行写操作的话，那么这里就会利用到上面讲到的操作系统提供的写时复制机制: 数据被复制一份，生成数据的副本。bgsave子进程把这个副本数据写入RDB文件，主线程仍然可以直接修改原来的数据。 使用RDB做快照需要注意的点 虽然RDB快照是bgsave子进程执行的，但如果执行快照的间隔太短，一方面频繁的写入数据到磁盘会给磁盘带来压力，另一方面，fork子进程这一过程是会阻塞主线程的，内存越大阻塞时间越长。 那么我们可以做增量快照，即做一次全量快照后，后续只需要记录修改的数据，对修改的数据做快照，减小做快照时候的开销。不过我们要是是以写操作为主的业务或者修改的键值对很多的话，记录被修改的数据同样会带来比较大的开销。 跟AOF相比，虽然RDB的恢复速度更快，但是快照的频率如何确定却也是一个问题。频率高了开销太大，频率小了又会造成数据的丢失。所以Redis 4.0提出了一个混合使用AOF日志和RDB快照的方法，即内存快照以一定的频率执行，两次快照之间用AOF记录这期间的操作。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:2","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#执行rdb快照时数据还可以修改吗"},{"categories":[],"content":" RDBRDB(Redis Database)是Redis数据持久化的另一种方式：内存快照，即记录某一时刻内存中的数据，类似于拍照时记录某一瞬间的形象。 和AOF相比，RDB恢复数据的效率更高，因为RDB快照记录的是实际数据，恢复时直接将RDB文件读入内存就行。 执行RDB快照时，数据还可以修改吗？快照就和自拍一样，拍照时如果自己动了，那么照片就糊了。那么对于RDB而言，它也不希望数据在‘动’。 如果在执行快照期间数据都不能修改的话，那么这肯定会给我们的业务造成很大的影响，这肯定是不能被接受的。 bgsave这一子进程是由主线程fork出来共享主线程内存数据的。如果主线程在执行快照期间是进行的读操作，那么主线程和bgsave子进程就互不影响，如果是执行写操作的话，那么这里就会利用到上面讲到的操作系统提供的写时复制机制: 数据被复制一份，生成数据的副本。bgsave子进程把这个副本数据写入RDB文件，主线程仍然可以直接修改原来的数据。 使用RDB做快照需要注意的点 虽然RDB快照是bgsave子进程执行的，但如果执行快照的间隔太短，一方面频繁的写入数据到磁盘会给磁盘带来压力，另一方面，fork子进程这一过程是会阻塞主线程的，内存越大阻塞时间越长。 那么我们可以做增量快照，即做一次全量快照后，后续只需要记录修改的数据，对修改的数据做快照，减小做快照时候的开销。不过我们要是是以写操作为主的业务或者修改的键值对很多的话，记录被修改的数据同样会带来比较大的开销。 跟AOF相比，虽然RDB的恢复速度更快，但是快照的频率如何确定却也是一个问题。频率高了开销太大，频率小了又会造成数据的丢失。所以Redis 4.0提出了一个混合使用AOF日志和RDB快照的方法，即内存快照以一定的频率执行，两次快照之间用AOF记录这期间的操作。 ","date":"2022-07-26","objectID":"/redis-aof-rdb/:2:2","series":["redis"],"tags":[],"title":"Redis数据持久化","uri":"/redis-aof-rdb/#使用rdb做快照需要注意的点"},{"categories":["go"],"content":"Gin框架与Radix Tree ","date":"2022-06-23","objectID":"/radix-tree/:0:0","series":["gin"],"tags":["go"],"title":"Gin框架与Radix-Tree","uri":"/radix-tree/#"},{"categories":["go"],"content":" Trie字典树，前缀树。是一种有序多叉树结构，利用字符串的公共前缀来减少查询的时间。 根节点不包含字符(目的是能包括所有字符串)，其余每个节点都只包含一个字符。 每个节点的子节点字符不同，保证唯一性。 ","date":"2022-06-23","objectID":"/radix-tree/:1:0","series":["gin"],"tags":["go"],"title":"Gin框架与Radix-Tree","uri":"/radix-tree/#trie"},{"categories":["go"],"content":" Radix Tree前缀压缩树，优化了Trie的空间。如果树中某个父节点的子节点唯一，那么其子节点将与父节点合并，即一个节点可以包含多个字符串。 假定我们有如下的路由注册信息: r := gin.Default() r.GET(\"/\", function1) r.GET(\"/php/\", function2) r.GET(\"/python/\", function3) r.GET(\"/article/\", function4) r.GET(\"/article/:id/\", function5) r.GET(\"/social/\", function6) r.GET(\"/social/github\", function6) 那么就可以得到一个GET方法对应的路由树。 与hash map不同，以上的这种树结构还允许使用例如:id这样的动态部分，因为实际上是根据路由参数进行匹配。 路由器为每一个请求方法管理一颗单独的树，这样比每个节点都保存一个hash map更节省空间。 ","date":"2022-06-23","objectID":"/radix-tree/:2:0","series":["gin"],"tags":["go"],"title":"Gin框架与Radix-Tree","uri":"/radix-tree/#radix-tree"},{"categories":[],"content":"图解一致性哈希算法 ","date":"2022-02-22","objectID":"/consistent_hash_algorithm/:0:0","series":["algorithm"],"tags":[],"title":"一致性哈希算法","uri":"/consistent_hash_algorithm/#"},{"categories":[],"content":" 负载均衡顾名思义，负载均衡就是分摊压力，例如在我们的大多数网站背后，都会不止有一台服务器在支撑网站的业务。毕竟一个人的力量是有限的，那一台服务器所能承受的压力、并发量、数据量也都是有限的，那么我们在拥有多台服务器后，要怎么分配‘压力’才显得合理呢？ 那么聪明的你肯定已经想到了，我们把压力平分给服务器就好了啊！就像发牌一样轮流转发请求给服务器不就行了嘛。对的，这其实就是一个简单的解决负载均衡的方法，但是我们还需要考虑到的一点是，每台服务器的配置是有所区别的，所以我们还可以给不同的机器根据配置设置权重，将配置差一点的机器权重设置得低一点，让配置好一点的服务器承受更多的压力，这种算法就被称之为加权轮询。 了解完负载均衡后，下面我们来看一个应用场景！ 假设我们有两万张商品的图片需要缓存，而我们手中有4台缓存服务器，那么根据我们上面讲到的负载均衡，你很容易就会想到将这2万张图片平均缓存到这4台服务器中。的确这样可以解决我们的问题，但是如果我们要访问某个缓存时，最坏的情况需要遍历4台缓存服务器，设想如果你是访问者，当我们的后台以这种方式去查询的时候，等待中的访问者是可以明显感受到效率太低的，我们做缓存的目的不就是减少等待时长吗？ 说到这里读者们应该都想到了哈希算法，对关键字进行哈希计算然后取模(确保结果小于等于哈希表的长度)，通过结果来选择对应的缓存服务器。 很好，看上去好像万无一失，所有的图片都可以有‘家’可归。But，这个商品购物网站越做越大，需要缓存的图片越来越多，4台服务器已经支撑不起了，这好办，多搞几台服务器不就好了，先上两台！如果我们还是使用同样的公式来决定该选择哪一台缓存服务器[hash(demo.jpg) % 6]，有没有突然发现，几乎所有需要缓存的图片的位置都发生了改变！同样我们如果我们因为机器故障要移除一台缓存服务器，那么几乎所有的数据都需要迁移！所以一致性哈希算法就该上场了~~ ","date":"2022-02-22","objectID":"/consistent_hash_algorithm/:1:0","series":["algorithm"],"tags":[],"title":"一致性哈希算法","uri":"/consistent_hash_algorithm/#负载均衡"},{"categories":[],"content":" 一致性哈希算法","date":"2022-02-22","objectID":"/consistent_hash_algorithm/:2:0","series":["algorithm"],"tags":[],"title":"一致性哈希算法","uri":"/consistent_hash_algorithm/#一致性哈希算法"},{"categories":[],"content":" 基本概念名字有相同之处，它们俩使用的方法也有相似之处。一致性哈希算法也是采用取模的方法，而刚才我们是对缓存服务器的数量取模，现在一致性哈希算法是对2^32取模。不对啊，那得需要多少台缓存服务器才能用得上这个算法啊？不急，我们来看看它的巧妙之处。 如果我们把使用一致性哈希算法取得的结果做成一个圆，那它是不是就变成这样了： 每一个使用一致性哈希算法得出的结果都可以在哈希环上找到一个自己的‘位置’，也就是说环上的点就是从0到2^32-1。 但是我们该怎么计算出自己的位置呢？以我们刚才的情景为例，分两步: 对存储节点做哈希映射。对应我们这里的对缓存服务器做哈希映射，也就是说把缓存服务器给分到哈希环上面去，例如用它的IP地址进行哈希 对数据做哈希映射。这里我们就要用到刚才说的对2^32取模 从图中我们也可以看到，计算出在哈希环上的位置后，往顺时针遇到的第一个节点，就是选择得缓存的服务器节点位置，即K1缓存在A上。那么我们再回到刚才遇到的问题，减少一个节点： 可以看到，只有缓存在B服务器上的图片收到了影响，需要迁移到节点C，增加节点同理。 也就是说，在一致性哈希算法中，增加或减少一个节点，只会影响哈希环上增加或删除的节点的后继节点(顺时针)，其他节点和数据并没有被影响。 但是上图中，看似服务器节点都均匀的分布到了哈希环上，但实际上一致性哈希算法并不能保证节点被均匀地分布在哈希环上，那么就可能产生这样一种情况： 可以看到，大量请求都打到了一个节点上，这还是负载均衡吗？ 再想一想，如果此时节点A扛不住了，那所有请求都打到了节点B上，那么很容易就引发了连锁雪崩！ 如果节点足够多的话，那是不是就会分布得更均匀一些？但实际中我们不会有那么多的节点，所以虚拟节点就派上用场了。 所谓虚拟节点就是实际节点的副本，首先将虚拟节点映射到哈希环上，再将虚拟节点映射到真实的节点，有了这两层映射关系这里就不再需要把真实节点再映射到哈希环上。 例如我们对ABCD四个节点分别设置3个虚拟节点： 节点数量变多后，分布就会更加均匀了。此时有请求访问到D-2，再通过D-2找到真实节点D，就能把请求打到D节点上了。 引入虚拟节点后，再有节点的增加或删除操作，就会有不同的节点来分担任务，提高了系统的稳定性。当然，也可以为配置好的节点分配更大的权重，设置更多的虚拟节点。 ","date":"2022-02-22","objectID":"/consistent_hash_algorithm/:2:1","series":["algorithm"],"tags":[],"title":"一致性哈希算法","uri":"/consistent_hash_algorithm/#基本概念"},{"categories":null,"content":"先来给各位看官大老爷表演一个Hello World package main import \"fmt\" func main() { fmt.Println(\"Hello World!\\n\") } ","date":"0001-01-01","objectID":"/about/:0:0","series":null,"tags":null,"title":"","uri":"/about/#"},{"categories":null,"content":" AboutAbout Author：严重拖延症患者😷 About Blog：文章没写多少，主题倒是换过很多次了。。。。 不过这次，作者打算就一直用这个主题，等到自己能写一个博客Theme出来再换吧，hhh~ Anyways，这个博客会更新一些笔者在学习过程中遇到的一些问题，一些知识的总结、笔记，以及一些好玩的东西！ 还不知道写啥了，等我想好了再来写吧! ","date":"0001-01-01","objectID":"/about/:1:0","series":null,"tags":null,"title":"","uri":"/about/#about"},{"categories":null,"content":" AboutAbout Author：严重拖延症患者😷 About Blog：文章没写多少，主题倒是换过很多次了。。。。 不过这次，作者打算就一直用这个主题，等到自己能写一个博客Theme出来再换吧，hhh~ Anyways，这个博客会更新一些笔者在学习过程中遇到的一些问题，一些知识的总结、笔记，以及一些好玩的东西！ 还不知道写啥了，等我想好了再来写吧! ","date":"0001-01-01","objectID":"/about/:1:0","series":null,"tags":null,"title":"","uri":"/about/#还不知道写啥了等我想好了再来写吧"},{"categories":null,"content":" You don’t have to connect to the Internet, only the cache pages available！ ","date":"0001-01-01","objectID":"/offline/:0:0","series":null,"tags":null,"title":"Offline","uri":"/offline/#"}]